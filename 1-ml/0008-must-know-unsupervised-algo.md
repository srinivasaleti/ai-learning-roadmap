# 📦 Must-Know Unsupervised Learning Algorithms (Simple English)

## 🔍 What is Unsupervised Learning?

- Machine learns from **data without labels**
- No correct answers are given
- Machine tries to **find patterns** on its own

---

## ✅ Must-Know Algorithms

### 1. 👥 K-Means Clustering

- 🔸 Groups similar data into **K clusters**
- 🔸 Example: Group customers into 3 categories
- 🔸 You decide number of groups (K)

---

### 2. 🐝 DBSCAN (Density-Based Spatial Clustering)

- 🔸 Finds **clusters of any shape**
- 🔸 Good when data has noise or odd shapes
- 🔸 No need to give number of clusters

---

### 3. 🌳 Hierarchical Clustering

- 🔸 Builds a tree of clusters
- 🔸 Groups data in steps (like family tree)
- 🔸 You can cut the tree at any level to get clusters

---

### 4. ✂️ PCA (Principal Component Analysis)

- 🔸 Reduces number of features (columns)
- 🔸 Keeps only important information
- 🔸 Example: From 100 features → down to 2 for chart

---

### 5. 🌈 t-SNE (t-distributed Stochastic Neighbor Embedding)

- 🔸 Used for **visualization**
- 🔸 Converts high-dimension data to 2D or 3D
- 🔸 Keeps similar points close in chart

---

### 6. 🎭 Autoencoders (Deep Learning)

- 🔸 Neural networks that learn to **compress** and **rebuild** data
- 🔸 Used for image compression, noise removal
- 🔸 Very useful in Generative AI!

---

## 🧠 Summary Table

| Algorithm               | Use Case                         | Notes                     |
| ----------------------- | -------------------------------- | ------------------------- |
| K-Means                 | Group similar items              | Need to choose K manually |
| DBSCAN                  | Cluster with noise/outliers      | No need to set K          |
| Hierarchical Clustering | Tree-like grouping               | Good for nested groups    |
| PCA                     | Reduce number of features        | Keeps important info only |
| t-SNE                   | Visualize high-dimensional data  | Great for 2D/3D charts    |

---
